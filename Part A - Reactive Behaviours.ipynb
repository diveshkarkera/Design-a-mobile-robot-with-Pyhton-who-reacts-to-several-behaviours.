{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A -  Reactive Behaviours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SPEED = 0.7\n",
    "RANDOM_SPEED = 0.4\n",
    "MAX_DEPTH = 600\n",
    "MAX_SPEED = 2\n",
    "HUMAN_DETECTION = 1\n",
    "BOTTLE_DETECTION = 44\n",
    "BACKPACK_DETECTION = 27\n",
    "CUP_DETECTION = 47\n",
    "ROTATING_TIME = 1\n",
    "LOVE = \"Love\"\n",
    "FEAR = \"Fear\"\n",
    "AGGRESSIVE = \"Aggressive\"\n",
    "CURIOUS = \"Curious\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorRT Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "from tensorrt_model import TRTModel\n",
    "from ssd_tensorrt import load_plugins, parse_boxes,TRT_INPUT_NAME, TRT_OUTPUT_NAME\n",
    "import ctypes\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "import ctypes\n",
    "    \n",
    "mean = 255.0 * np.array([0.5, 0.5, 0.5])\n",
    "stdev = 255.0 * np.array([0.5, 0.5, 0.5])\n",
    "\n",
    "def bgr8_to_ssd_input(camera_value):\n",
    "    x = camera_value\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1)).astype(np.float32)\n",
    "    x -= mean[:, None, None]\n",
    "    x /= stdev[:, None, None]\n",
    "    return x[None, ...]\n",
    "\n",
    "def draw_box(bbox, image, rgb):\n",
    "    cv2.rectangle(image, (int(width * bbox[0]), int(height * bbox[1])), (int(width * bbox[2]), int(height * bbox[3])), rgb, 2)\n",
    "\n",
    "class ObjectDetector(object):\n",
    "    \n",
    "    def __init__(self, engine_path, preprocess_fn=bgr8_to_ssd_input):\n",
    "        logger = trt.Logger()\n",
    "        trt.init_libnvinfer_plugins(logger, '')\n",
    "        load_plugins()\n",
    "        self.trt_model = TRTModel(engine_path, input_names=[TRT_INPUT_NAME],output_names=[TRT_OUTPUT_NAME, TRT_OUTPUT_NAME + '_1'])\n",
    "        self.preprocess_fn = preprocess_fn\n",
    "        \n",
    "    def execute(self, *inputs):\n",
    "        trt_outputs = self.trt_model(self.preprocess_fn(*inputs))\n",
    "        return parse_boxes(trt_outputs)\n",
    "    \n",
    "    def __call__(self, *inputs):\n",
    "        return self.execute(*inputs)\n",
    "\n",
    "model = ObjectDetector('ssd_mobilenet_v2_coco.engine')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Behaviour Parent class with all its child classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Behaviours:\n",
    "    \"\"\"\n",
    "        Main Parent class for all behaviours. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.turn_gain = 0\n",
    "        self.speed = DEFAULT_SPEED\n",
    "        self.randomVal = random.uniform(1,1.5)\n",
    "        self.startTime = cv2.getTickCount()\n",
    "        self.predefined_targets ={\n",
    "            1: {\n",
    "                \"name\" : \"HUMAN\",\n",
    "                \"status\" : \"NOT_VISITED\"\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def move(self, center, movement):\n",
    "        \"\"\"\n",
    "            Move robot based on the movement.\n",
    "            \n",
    "            :param center : tuple containing (x,y) coordinate of the center of the target object.\n",
    "            :param movement : List containing the direction and turn gain in which the obot has to move.\n",
    "            :return : None\n",
    "        \"\"\" \n",
    "        left_speed = float(self.speed + movement[1] * center[0])\n",
    "        right_speed = float(self.speed - movement[1] * center[0])\n",
    "        robot.set_motors(left_speed, right_speed, left_speed, right_speed)\n",
    "    \n",
    "    def get_min_depth(self, bbox):\n",
    "        depth_image = np.copy(camera.depth_image)\n",
    "        #we only consider the central area of the vision sensor\n",
    "        depth_image[:int(height * bbox[1]),:]=0\n",
    "        depth_image[int(height * bbox[3]):,:]=0\n",
    "        depth_image[:,:int(width * bbox[0])]=0\n",
    "        depth_image[:,int(width * bbox[2]):]=0\n",
    "\n",
    "        #For object avoidance, we don't consider the distance that are lower than 100mm or bigger than 1000mm\n",
    "        depth_image[depth_image<100]=0\n",
    "        depth_image[depth_image>1000]=0\n",
    "\n",
    "        #If all of the values in the depth image is 0, the depth[depth!=0] command will fail\n",
    "        #we set a specific value here to prevent this failure\n",
    "        depth_image[0,0]=2000\n",
    "\n",
    "        return(depth_image[depth_image!=0].min())\n",
    "\n",
    "    def turn_left(self, speed = 0.1):    \n",
    "        \"\"\"\n",
    "            Randomly moves the Robot.\n",
    "        \"\"\"\n",
    "        left_speed = float(speed - 0.4)\n",
    "        right_speed = float(speed + 0.4)\n",
    "        robot.set_motors(left_speed, right_speed, left_speed, right_speed)\n",
    "    \n",
    "    def move_robot_randomly(self):\n",
    "        currTime = cv2.getTickCount()\n",
    "        deltaTime = (currTime - self.startTime) / cv2.getTickFrequency()\n",
    "      \n",
    "        if deltaTime >= 0 and deltaTime <= self.randomVal:\n",
    "            self.turn_left()\n",
    "        elif deltaTime > 2:\n",
    "            self.startTime = cv2.getTickCount()\n",
    "            self.randomVal = random.uniform(1,1.5)\n",
    "        else:\n",
    "            robot.forward(0.3)\n",
    "        return\n",
    "    \n",
    "    def set_speed(self,depth):\n",
    "        return None\n",
    "    \n",
    "    def get_target(self, object_detections):\n",
    "        idx = 0\n",
    "        target= None\n",
    "        # Depths of all the detections\n",
    "        detection_depths = np.array([])\n",
    "        \n",
    "        for det in object_detections:\n",
    "            bbox = det['bbox']\n",
    "            detection_depths = np.append(detection_depths, self.get_min_depth(bbox))\n",
    "        \n",
    "        if not len(object_detections):\n",
    "            return idx, target\n",
    "        \n",
    "        # get the min depth of human bboxs\n",
    "        index_value = np.where(detection_depths == np.amin(detection_depths))\n",
    "        idx = index_value[0][0]\n",
    "        target = object_detections[idx]\n",
    "        \n",
    "        if detection_depths[idx] > 800:\n",
    "            return 0, None\n",
    "        \n",
    "        \n",
    "        camera.behaviour.set_speed(detection_depths[idx])\n",
    "        return idx, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Love (Behaviours):\n",
    "    \"\"\"\n",
    "        Subclass of Behaviours. Implements the Love behaviour of robot. Follows the target \n",
    "        and gradually slows down as it goes closer to the target.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def move(self, center, movement):\n",
    "        # calling the super class move() function         \n",
    "        super().move(center, movement)\n",
    "        \n",
    "    def set_speed(self,depth):\n",
    "        \"\"\"\n",
    "            Defines the speed of the Robot based on the depth between the robot and target object, as to display a \n",
    "            gradually decrease of speed as it moves closer to target. \n",
    "            \n",
    "            :param depth : The depth between the robot and the target object.\n",
    "            :return : None\n",
    "        \"\"\"\n",
    "        if depth <= MAX_DEPTH:\n",
    "            self.speed = 0\n",
    "        elif (depth <=  MAX_DEPTH + 50):\n",
    "            self.speed = DEFAULT_SPEED - DEFAULT_SPEED * 0.85 \n",
    "        elif (depth <=  MAX_DEPTH + 100):\n",
    "            self.speed = DEFAULT_SPEED - DEFAULT_SPEED * 0.75\n",
    "        elif (depth <= MAX_DEPTH + 150):\n",
    "            self.speed = DEFAULT_SPEED - DEFAULT_SPEED * 0.55  \n",
    "        elif (depth <= MAX_DEPTH + 200):\n",
    "            self.speed = DEFAULT_SPEED - DEFAULT_SPEED * 0.35\n",
    "        else:\n",
    "            self.speed = DEFAULT_SPEED\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aggressive (Behaviours):\n",
    "    \"\"\"\n",
    "        Implements the Aggressive behaviour of the robot. Move towards target at Max speed and stop immediately,\n",
    "        as it reaches the target.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #  Pre-define targets, the robot will show aggressive behaviour with these targets.\n",
    "        self.predefined_targets ={\n",
    "            BACKPACK_DETECTION: {\n",
    "                \"name\" : \"HUMAN\",\n",
    "                \"status\" : \"NOT_VISITED\"\n",
    "            }\n",
    "        }\n",
    "    def move(self, center, movement):\n",
    "        \"\"\"\n",
    "            Calling the parent/super class move function.\n",
    "        \"\"\"\n",
    "        new_movement = movement[0], movement[1]*5\n",
    "        super().move(center, new_movement)\n",
    "        \n",
    "    def set_speed(self, depth):\n",
    "        \"\"\"\n",
    "            Defines the speed of the robot based on the depth of robot from its target. Makes the speed MAX, \n",
    "            when the robot follows the target, and 0 as it becomes lesser than or equal to the Maximum depth.\n",
    "            Displaying aggressive behaviour of the robot.\n",
    "            \n",
    "            :param depth : The depth between the robot and the target object.\n",
    "            :return : None\n",
    "        \"\"\"\n",
    "        if depth <= MAX_DEPTH:\n",
    "            self.speed = 0\n",
    "        else:\n",
    "            self.speed = MAX_SPEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fear (Behaviours):\n",
    "    \"\"\"\n",
    "        Implements the Fear behaviour of the robot. Turns 180° as it is inside target's range, ie. MAX_DEPTH.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.turn_flag = False\n",
    "        self.isRobotTurning = False\n",
    "        self.startTime = cv2.getTickCount()\n",
    "        #  Pre-define targets, the robot will show fear behaviour with these targets.\n",
    "        self.predefined_targets ={\n",
    "            44: {\n",
    "                \"name\" : \"BOTTLE\",\n",
    "                \"status\" : \"NOT_VISITED\"\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def set_speed(self, depth):\n",
    "        \"\"\"\n",
    "            Defines the speed of the robot based on the depth of robot from its target. Makes the speed MAX, \n",
    "            when the robot follows the target, and 0 as it becomes lesser than or equal to the Maximum depth.\n",
    "            Displaying aggressive behaviour of the robot.\n",
    "            \n",
    "            :param depth : The depth between the robot and the target object.\n",
    "            :return : None\n",
    "        \"\"\"\n",
    "        if depth <= MAX_DEPTH:\n",
    "            self.turn_flag = True\n",
    "        elif self.isRobotTurning == False:\n",
    "            self.turn_flag = False \n",
    "            \n",
    "    def move(self, center, movement):\n",
    "        \"\"\"\n",
    "            Rotates the robot 180°, as it's get inside the target's range, then moves the robot randomly.\n",
    "        \"\"\"\n",
    "        # Testing: Rotate the robot 180 degree.\n",
    "        if self.turn_flag:\n",
    "            self.isRobotTurning = True\n",
    "            currTime = cv2.getTickCount()\n",
    "            deltaTime = (currTime - self.startTime) / cv2.getTickFrequency()\n",
    "            if deltaTime <= 6:\n",
    "                robot.left(MAX_SPEED)\n",
    "            else: \n",
    "                robot.stop()\n",
    "                self.isRobotTurning  = False\n",
    "        else:\n",
    "            self.isRobotTurning  = False\n",
    "            self.startTime = cv2.getTickCount()\n",
    "            super().move_robot_randomly()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Curious (Behaviours):\n",
    "    \"\"\"\n",
    "        Child class of Behaviours class. Implements the curious behaviour of the robot class.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.target_reached = False\n",
    "        # Pre-defined target objects dictionary, for displaying curious attribute of the robot.\n",
    "        self.predefined_targets ={\n",
    "            44: {\n",
    "                \"name\" : \"BOTTLE\",\n",
    "                \"status\" : \"NOT_VISITED\"\n",
    "            },\n",
    "            1: {\n",
    "                \"name\" : \"BACKPACK\",\n",
    "                \"status\" : \"NOT_VISITED\"\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def set_speed(self, depth):    \n",
    "        \"\"\"\n",
    "        Defines the speed of the robot. And status of the target object becomes \"VISITED\", once depth reaches it\n",
    "        maximum value.\n",
    "        \n",
    "        :param depth : The depth between the robot and the target object.\n",
    "        :return : None\n",
    "        \"\"\"\n",
    "        if depth <= MAX_DEPTH:\n",
    "            self.speed = 0\n",
    "            self.target_reached = True\n",
    "            for i in self.predefined_targets:\n",
    "                if self.predefined_targets[i][\"status\"] == \"VISITING\":\n",
    "                    self.predefined_targets[i][\"status\"] = \"VISITED\"   \n",
    "                    break\n",
    "        else:\n",
    "            self.speed = DEFAULT_SPEED\n",
    "        return None\n",
    "    \n",
    "    def get_target(self, object_detections):\n",
    "        \"\"\"\n",
    "            Returns the element that has a status \"VISITING\", if object_detections contains no such predefined_target, it returns \n",
    "            a random element as target with its index from the predefined_targets, that object_detections contains.\n",
    "            \n",
    "            :param object_detections : Dictionary containing all the predefined_target objects that are present \n",
    "                                      in the camera frame.\n",
    "            :return target : the element from the object_detections dictionary that has a status \"VISTING\".\n",
    "            :return idx    : the index number of the target element.\n",
    "                    \n",
    "        \"\"\"\n",
    "        idx = 0\n",
    "        target= None\n",
    "                \n",
    "        for det in self.predefined_targets:\n",
    "            if self.predefined_targets[det][\"status\"] == \"VISITING\":\n",
    "                idx , target = super().get_target([i for i in object_detections if i['label'] == det])\n",
    "                if target is None:\n",
    "                    break\n",
    "                    \n",
    "                idx = np.where(object_detections == target)[0]\n",
    "                return idx, target\n",
    "                \n",
    "        if target is None:\n",
    "            random_index = random.randint(0,len(object_detections) - 1)\n",
    "            target = object_detections[random_index]\n",
    "            idx = random_index\n",
    "            self.predefined_targets[target['label']][\"status\"] = \"VISITING\"\n",
    "\n",
    "        return idx, target\n",
    "    \n",
    "\n",
    "    def move(self, center, movement):\n",
    "        \"\"\"\n",
    "            Stop robot as it gets in the target's range for 2 sec and then rotates it 180°, else \n",
    "            follows the target untill it reach. \n",
    "        \"\"\"\n",
    "        if self.target_reached:\n",
    "            robot.stop()\n",
    "            time.sleep(2)\n",
    "            # Rotating the robot 180 degrees             \n",
    "            robot.left(DEFAULT_SPEED)\n",
    "            time.sleep(ROTATING_TIME)\n",
    "            self.speed = DEFAULT_SPEED\n",
    "            self.target_reached = False\n",
    "            \n",
    "        super().move(center, movement)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the camera instance for the Intel realsense sensor D435i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use traitlets and widgets to display the image in Jupyter Notebook\n",
    "import traitlets\n",
    "from traitlets.config.configurable import SingletonConfigurable\n",
    "\n",
    "#use opencv to covert the depth image to RGB image for displaying purpose\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#using realsense to capture the color and depth image\n",
    "import pyrealsense2 as rs\n",
    "\n",
    "#multi-threading is used to capture the image in real time performance\n",
    "import threading\n",
    "\n",
    "class Camera(SingletonConfigurable):\n",
    "    \n",
    "    #this changing of this value will be captured by traitlets\n",
    "    color_value = traitlets.Any()\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Camera, self).__init__()\n",
    "        \n",
    "        #configure the color and depth sensor\n",
    "        self.pipeline = rs.pipeline()\n",
    "        self.configuration = rs.config()  \n",
    "        \n",
    "        #set resolution for the color camera\n",
    "        self.color_width = 640\n",
    "        self.color_height = 480\n",
    "        self.color_fps = 30\n",
    "        self.configuration.enable_stream(rs.stream.color, self.color_width, self.color_height, rs.format.bgr8, self.color_fps)\n",
    "\n",
    "        #set resolution for the depth camera\n",
    "        self.depth_width = 640\n",
    "        self.depth_height = 480\n",
    "        self.depth_fps = 30\n",
    "        self.configuration.enable_stream(rs.stream.depth, self.depth_width, self.depth_height, rs.format.z16, self.depth_fps)\n",
    "\n",
    "        #flag to control the thread\n",
    "        self.thread_runnning_flag = False\n",
    "        \n",
    "        #start the RGBD sensor\n",
    "        self.pipeline.start(self.configuration)\n",
    "        self.pipeline_started = True\n",
    "        frames = self.pipeline.wait_for_frames()\n",
    "\n",
    "        #start capture the first color image\n",
    "        color_frame = frames.get_color_frame()   \n",
    "        image = np.asanyarray(color_frame.get_data())\n",
    "        self.color_value = image\n",
    "\n",
    "        #start capture the first depth image\n",
    "        depth_frame = frames.get_depth_frame()           \n",
    "        depth_image = np.asanyarray(depth_frame.get_data())\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "        self.depth_value = depth_colormap   \n",
    "\n",
    "        # Intialising Behaviour class.\n",
    "        self.behaviour = Behaviours()\n",
    "        self.target_detected = False\n",
    "        self.target_center = ()\n",
    "        \n",
    "        \n",
    "    def _capture_frames(self):\n",
    "        while(self.thread_runnning_flag==True): #continue until the thread_runnning_flag is set to be False\n",
    "            frames = self.pipeline.wait_for_frames() #receive data from RGBD sensor\n",
    "            \n",
    "            color_frame = frames.get_color_frame() #get the color image\n",
    "            image = np.asanyarray(color_frame.get_data()) #convert color image to numpy array\n",
    "            self.color_value = image #assign the numpy array image to the color_value variable \n",
    "\n",
    "            depth_frame = frames.get_depth_frame() #get the depth image           \n",
    "            depth_image = np.asanyarray(depth_frame.get_data()) #convert depth data to numpy array\n",
    "            #conver depth data to BGR image for displaying purpose\n",
    "            depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "            self.depth_value = depth_colormap #assign the color BGR image to the depth value\n",
    "            cv2.putText(depth_colormap, str(depth_image[240,320]), (320,240), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2, cv2.LINE_AA)            \n",
    "            self.depth_image = depth_image \n",
    "                    \n",
    "                \n",
    "    def start(self): #start the data capture thread\n",
    "        if self.thread_runnning_flag == False: #only process if no thread is running yet\n",
    "            self.thread_runnning_flag=True #flag to control the operation of the _capture_frames function\n",
    "            self.thread = threading.Thread(target=self._capture_frames) #link thread with the function\n",
    "            self.thread.start() #start the thread\n",
    "\n",
    "    def stop(self): #stop the data capture thread\n",
    "        if self.thread_runnning_flag == True:\n",
    "            self.thread_runnning_flag = False #exit the while loop in the _capture_frames\n",
    "            self.thread.join() #wait the exiting of the thread       \n",
    "\n",
    "def bgr8_to_jpeg(value):#convert numpy array to jpeg coded data for displaying \n",
    "    return bytes(cv2.imencode('.jpg',value)[1])\n",
    "\n",
    "#create a camera object\n",
    "camera = Camera.instance()\n",
    "camera.start() # start capturing the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform object detection and display the results on widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "width = 640\n",
    "height = 480\n",
    "\n",
    "width_left_edge = 190\n",
    "width_right_edge = 450\n",
    "\n",
    "image_widget = widgets.Image(format='jpeg', width=width, height=height)\n",
    "\n",
    "# Creating Drop down menu for target objects.\n",
    "dropDownMenu = widgets.Dropdown(\n",
    "    options=[LOVE, FEAR, AGGRESSIVE, CURIOUS],\n",
    "    value=LOVE,\n",
    "    description='Behaviour:',\n",
    ")\n",
    "\n",
    "# Default behaviour is set to LOVE\n",
    "camera.behaviour = Love()\n",
    "\n",
    "def onItemSelected(item):\n",
    "    if item['type'] == 'change' and item['name'] == 'value':\n",
    "        selected_behaviour = item['new']\n",
    "        if selected_behaviour == LOVE:\n",
    "            camera.behaviour = Love()\n",
    "        elif selected_behaviour == FEAR:\n",
    "            camera.behaviour = Fear()\n",
    "        elif selected_behaviour == AGGRESSIVE:\n",
    "            camera.behaviour = Aggressive()\n",
    "        elif selected_behaviour == CURIOUS:\n",
    "            camera.behaviour = Curious()\n",
    "        else:\n",
    "            print(\"Something went wrong!\")\n",
    "\n",
    "# Attaching a listener for drop down menu\n",
    "dropDownMenu.observe(onItemSelected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN ROBOT PROCESSING CODE : Perform object detection and controls the robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from RobotClass import Robot\n",
    "\n",
    "# Initializes the Robot class\n",
    "robot = Robot()\n",
    "\n",
    "# https://github.com/NVIDIA-AI-IOT/jetbot/blob/master/notebooks/object_following/live_demo.ipynb\n",
    "def get_center(bbox):\n",
    "    \"\"\"Computes the center x, y coordinates of the object\"\"\"\n",
    "    center_x = (bbox[0] + bbox[2]) / 2.0 - 0.5\n",
    "    center_y = (bbox[1] + bbox[3]) / 2.0 - 0.5\n",
    "    return (center_x, center_y)\n",
    "\n",
    "def detect_section(coord):\n",
    "    \"\"\"\n",
    "        Detects what section the object is in and calculates the turn gain.\n",
    "        turn gain is between 0 and 1\n",
    "    \"\"\"\n",
    "    direction = \"CENTER\"\n",
    "    turn_gain = 0\n",
    "    center_x = coord[0]\n",
    "    \n",
    "    if(center_x < width_left_edge):\n",
    "        turn_gain = (width_left_edge - center_x) / width_left_edge\n",
    "        direction= \"LEFT\"\n",
    "    elif(center_x > width_right_edge):\n",
    "        turn_gain = (center_x - width_right_edge) / width_left_edge\n",
    "        direction= \"RIGHT\"\n",
    "   \n",
    "    return direction, turn_gain\n",
    "\n",
    "def processing(change):\n",
    "    \"\"\"\n",
    "        Runs every Frame on a different thread (other than the main thread)\n",
    "    \"\"\"\n",
    "    image = change['new']\n",
    "    \n",
    "    imgsized= cv2.resize(image,(300,300))\n",
    "    \n",
    "    # compute all detected objects\n",
    "    detections = model(imgsized)\n",
    "    \n",
    "    # https://github.com/tensorflow/models/blob/master/research/object_detection/data/mscoco_complete_label_map.pbtxt\n",
    "    \n",
    "    # Will return us a object_detections dictionary of the objects that are present in predefined_target \n",
    "    # from every objects inside the camera frame. So, we only detect those objects that are present inside the\n",
    "    # object_detections dictionary.\n",
    "    predefined_keys = [d for d in camera.behaviour.predefined_targets if camera.behaviour.predefined_targets[d]['status'] != \"VISITED\"]\n",
    "    object_detections = [d for d in detections[0] if d['label'] in predefined_keys]\n",
    "        \n",
    "    if len(object_detections) == 0:\n",
    "        camera.target_detected = False\n",
    "        camera.target_center = None\n",
    "    else:\n",
    "        \n",
    "        idx, target = camera.behaviour.get_target(object_detections)\n",
    "        \n",
    "        if target is not None:\n",
    "            \n",
    "            bbox = target['bbox']\n",
    "\n",
    "            # Display rectangle on the camera widget        \n",
    "            draw_box(bbox, image, (0,0,255))\n",
    "            # When the robot is too near to the target object\n",
    "            center = get_center(bbox)\n",
    "\n",
    "            # set camera speed based on depth   \n",
    "            camera.target_detected = True\n",
    "            camera.target_center = center\n",
    "        else:\n",
    "            camera.target_detected = False\n",
    "            camera.target_center = (0,0)\n",
    "            \n",
    "    # Move towards target by calling the move() function based on the type of behaviour object. \n",
    "    if(camera.target_detected):\n",
    "        center = camera.target_center\n",
    "        movement = detect_section(center)\n",
    "        camera.behaviour.move(center, movement)        \n",
    "    else:\n",
    "        # Moves robot randomly         \n",
    "        camera.behaviour.move_robot_randomly()\n",
    "                              \n",
    "                          \n",
    "    image_widget.value = bgr8_to_jpeg(image)\n",
    "    \n",
    "#the camera.observe function will monitor the color_value variable. If this value changes, the excecute function will be excuted.\n",
    "camera.observe(processing, names='color_value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the Camera Image widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4484498fb1ac4d3e956ab4bfc5609c3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Behaviour:', index=1, options=('Love', 'Fear', 'Aggressive', 'Curious'), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(widgets.VBox([\n",
    "    dropDownMenu,\n",
    "    image_widget]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distaches the observe listener from the camera object and stops the robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.unobserve_all()\n",
    "camera.stop()\n",
    "camera.start()\n",
    "time.sleep(1.0)\n",
    "robot.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
